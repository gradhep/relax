{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import relaxed\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.random import PRNGKey, multivariate_normal\n",
    "import pyhf\n",
    "from typing import Callable, Any\n",
    "from functools import partial\n",
    "\n",
    "Array = jnp.ndarray\n",
    "\n",
    "\n",
    "def generate_data(\n",
    "    rng=0,\n",
    "    num_points=10000,\n",
    "    sig_mean=(-1, 1),\n",
    "    bup_mean=(4.5, 2),\n",
    "    bdown_mean=(-2.5, -2.5),\n",
    "    b_mean=(0, 0),\n",
    "):\n",
    "    sig = multivariate_normal(\n",
    "        PRNGKey(rng),\n",
    "        jnp.asarray(sig_mean),\n",
    "        jnp.asarray([[1, 0], [0, 1]]),\n",
    "        shape=(num_points,),\n",
    "    )\n",
    "    bkg_up = multivariate_normal(\n",
    "        PRNGKey(rng),\n",
    "        jnp.asarray(bup_mean),\n",
    "        jnp.asarray([[1, 0], [0, 1]]),\n",
    "        shape=(num_points,),\n",
    "    )\n",
    "    bkg_down = multivariate_normal(\n",
    "        PRNGKey(rng),\n",
    "        jnp.asarray(bdown_mean),\n",
    "        jnp.asarray([[1, 0], [0, 1]]),\n",
    "        shape=(num_points,),\n",
    "    )\n",
    "\n",
    "    bkg_nom = multivariate_normal(\n",
    "        PRNGKey(rng),\n",
    "        jnp.asarray(b_mean),\n",
    "        jnp.asarray([[1, 0], [0, 1]]),\n",
    "        shape=(num_points,),\n",
    "    )\n",
    "    return dict(sig=sig, bkg_nominal=bkg_nom, bkg_up=bkg_up, bkg_down=bkg_down)\n",
    "\n",
    "\n",
    "def hists_from_pars(\n",
    "    pars: dict[str, Array],\n",
    "    data: dict[str, Array],\n",
    "    nn: Callable,\n",
    "    bandwidth: float,\n",
    "    bins: Array | None = None,\n",
    "    scale_factors: dict[str, float] | None = None,\n",
    ") -> dict[str, Array]:\n",
    "    \"\"\"Function that takes in data + analysis config parameters, and constructs yields.\"\"\"\n",
    "    nn_output = {k: nn(pars[\"nn_pars\"], data[k]).ravel() for k in data}\n",
    "    make_hist = partial(\n",
    "        relaxed.hist, bandwidth=bandwidth, bins=pars[\"bins\"] if \"bins\" in pars else bins\n",
    "    )\n",
    "    scale_factors = scale_factors or {k: 1.0 for k in nn_output}\n",
    "    hists = {k: make_hist(nn_output[k]) * scale_factors[k] for k in nn_output}\n",
    "    return hists\n",
    "\n",
    "\n",
    "def model_from_hists(hists: dict[str, Array]) -> pyhf.Model:\n",
    "    \"\"\"How to make your HistFactory model from your histograms.\"\"\"\n",
    "    spec = {\n",
    "        \"channels\": [\n",
    "            {\n",
    "                \"name\": \"singlechannel\",\n",
    "                \"samples\": [\n",
    "                    {\n",
    "                        \"name\": \"signal\",\n",
    "                        \"data\": hists[\"sig\"],\n",
    "                        \"modifiers\": [\n",
    "                            {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None},\n",
    "                        ],\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"background\",\n",
    "                        \"data\": hists[\"bkg_nominal\"],\n",
    "                        \"modifiers\": [\n",
    "                            {\n",
    "                                \"name\": \"correlated_bkg_uncertainty\",\n",
    "                                \"type\": \"histosys\",\n",
    "                                \"data\": {\n",
    "                                    \"hi_data\": hists[\"bkg_up\"],\n",
    "                                    \"lo_data\": hists[\"bkg_down\"],\n",
    "                                },\n",
    "                            },\n",
    "                        ],\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "    return pyhf.Model(spec, validate=False)\n",
    "\n",
    "\n",
    "def loss_from_model(\n",
    "    model: pyhf.Model,\n",
    "    loss: str | Callable[[dict[str, Any]], float] = \"neos\",\n",
    "    fit_lr=1e-3,\n",
    "):\n",
    "    if isinstance(loss, Callable):\n",
    "        # everything\n",
    "        return 0\n",
    "    # loss specific\n",
    "    if loss.tolower() == \"discovery\":\n",
    "        test_stat = \"q0\"\n",
    "        test_poi = 0.0\n",
    "        hypothesis_pars = (\n",
    "            jnp.asarray(model.config.suggested_init())\n",
    "            .at[model.config.poi_index]\n",
    "            .set(1.0)\n",
    "        )\n",
    "    elif loss.tolower() in [\"neos\", \"cls\"]:\n",
    "        test_stat = \"q\"\n",
    "        test_poi = 1.0\n",
    "        hypothesis_pars = (\n",
    "            jnp.asarray(model.config.suggested_init())\n",
    "            .at[model.config.poi_index]\n",
    "            .set(0.0)\n",
    "        )\n",
    "    elif loss.tolower() in [\"inferno\", \"poi_uncert\", \"mu_uncert\"]:\n",
    "        test_stat = \"q0\"\n",
    "        test_poi = 0.0\n",
    "        hypothesis_pars = (\n",
    "            jnp.asarray(model.config.suggested_init())\n",
    "            .at[model.config.poi_index]\n",
    "            .set(1.0)\n",
    "        )\n",
    "        observed_hist = jnp.asarray(model.expected_data(hypothesis_pars))\n",
    "        return relaxed.cramer_rao_uncert(model, hypothesis_pars, observed_hist)[\n",
    "            model.config.poi_index\n",
    "        ]\n",
    "    elif loss.tolower() in [\"general_variance\"]:\n",
    "        test_poi = 0.0\n",
    "        hypothesis_pars = (\n",
    "            jnp.asarray(model.config.suggested_init())\n",
    "            .at[model.config.poi_index]\n",
    "            .set(1.0)\n",
    "        )\n",
    "        observed_hist = jnp.asarray(model.expected_data(hypothesis_pars))\n",
    "        return jnp.linalg.det(\n",
    "            jnp.linalg.inv(relaxed.fisher_info(model, hypothesis_pars, observed_hist))\n",
    "        )\n",
    "\n",
    "    observed_hist = jnp.asarray(model.expected_data(hypothesis_pars))\n",
    "    return relaxed.infer.hypotest(\n",
    "        test_poi=test_poi,\n",
    "        data=observed_hist,\n",
    "        model=model,\n",
    "        test_stat=test_stat,\n",
    "        expected_pars=hypothesis_pars,\n",
    "        lr=fit_lr,\n",
    "    )\n",
    "\n",
    "\n",
    "def pipeline(pars, data, nn, loss, bandwidth):\n",
    "    hists = hists_from_pars(pars=pars, nn=nn, data=data, bandwidth=bandwidth)\n",
    "    model = model_from_hists(hists)\n",
    "    return loss_from_model(model, loss=loss)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
